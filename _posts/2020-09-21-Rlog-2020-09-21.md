---
layout: post
tag: rlog
---

## Todo

Chap 1 of the Bandit Algorithm book

## Done

Sec 3.6 of the PLG book (no pset)

Skipping Sec 3.7

## Notes and Questions

1) In the proof of Theorem 3.5: Why are $l(f_i, 0)$ and $l(f_i, 1)$ in $S$?

2) Oracle Inequality for Mixable Losses: unclear how the existence of an accumulation point $\hat{p} \in \mathcal{D}$ leads to the inequality after that. Maybe I should learn a bit topology?

3) Figure 3.4: there are mixable but not exp-concave lossess (examples?), so the figure is not entirely correct (Nishant).

4) Unclear about the motivation of the exponential potential $\Phi_\eta(u) = \frac{1}{\eta}\ln{1}$ in the weighted average forecaster and the greedy forecaster. In Chap 2 (page 10) about the weighted average forecaster, the book says "it is convenient to introduce also a potential function $\Phi$...". In Chap 3 Sec 3.4, the book says this potential function is a "smooth" version of the $\max_{i=1,...,N}R_{i,t}$. Not sure where it comes from. Looks like a mathematical tool to show the bound is $O(ln{N})$ rather than a quantity with real meaning.
